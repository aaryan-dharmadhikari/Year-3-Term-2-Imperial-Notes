## We now Move onto NNs
![[Pasted image 20240226094051.png]]
### Perceptron
![[Pasted image 20240226094105.png]]
#### Multi-layer Perceptron
![[Pasted image 20240226094211.png]]
- Fundamentally little has changed with neural networks.
- Optimisations have taken the form of:
![[Pasted image 20240226094259.png]]
![[Pasted image 20240226094324.png]]
- MLP is just a composition of several layers of neurons
![[Pasted image 20240226094407.png]]
### Training a NN
![[Pasted image 20240226094455.png]]
- A loss function measures the disparity between predicted and actual values in a model, guiding optimization towards accurate predictions.
![[Pasted image 20240226094703.png]]
![[Pasted image 20240226094735.png]]
### Loss Functions
![[Pasted image 20240226094751.png]]
### Binary Classification
![[Pasted image 20240226094841.png]]
![[Pasted image 20240226094912.png]]
![[Pasted image 20240226094924.png]]
### Multi-class Classification
![[Pasted image 20240226095015.png]]
![[Pasted image 20240226095036.png]]
### Sigmoid Vs Softmax
![[Pasted image 20240226095124.png]]
