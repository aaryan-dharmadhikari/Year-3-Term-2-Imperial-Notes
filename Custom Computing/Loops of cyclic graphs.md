- AIM: Look at how software loops might map to hardware and the various ways of doing this
![[Pasted image 20240304124907.png]]
- Problem is that this feedback introduces a *loop-carried* dependency: each loop depends on the value of the "sum" variable in the previous iteration.
- Host: Limited by PCIe for communication
- Off-chip memory: limited by size and bandwidth
- On-chip: Expensive and limited memory
![[Pasted image 20240304125649.png]]
![[Pasted image 20240304125844.png]]
- One *Computation-to-Memory Access*, which is not good
- Bottleneck is mem/bus throughput
- Easy to fit as one element per iteration
- working set size = 0
- Implicit in MaxCompiler
![[Pasted image 20240304130121.png]]
An array-access loop with stride-1 memory accesses Recall from the second lecture that sequences of numbers can be generated by counters – the loop-carried dependency in the count variable can be implemented by one counter. 
- Computation-to-MemoryAccess = 2 (still low) 
- Bottleneck is memory or bus throughput 
- Working set size = 1 (loop counter) 
- Note: Stream Loop is implicit in the MaxCompiler code
![[Pasted image 20240304130714.png]]
- Implicitly loop over A and B using stream loops
![[Pasted image 20240304130919.png]]
This example calculates a Newton-Raphson iteration. If the number of iterations is small and fixed, use a Java for-loop to implement the inner C for-loop. Since the Java for-loop runs at hardware build time, we call this loop unrolling: we build one piece of hardware per loop iteration.
- Array-access (i) & Loop-carried dependency (v) 
- Computation-to-MemoryAccess = 12 (better) 
- Working set size = 0
![[Pasted image 20240304131213.png]]
![[Pasted image 20240304131400.png]]
![[Pasted image 20240304131432.png]]![[Pasted image 20240304131951.png]]
- Note we create an unconnected DFE node (scalarType.newInstance(this)). Then create feedback using the connect method of the DFEVar carry. If you try this, you’ll find the compiler can’t schedule the design unless the stream offset is negative, and less than a certain number: 13 in this example. 
- Where does ‘13’ come from? It’s the latency of the adder plus the multiplexer, for this particular datatype.
![[Pasted image 20240304132337.png]]
![[Pasted image 20240304133639.png]]
- Not examinable, but showing how we may find latency in MaxJ
![[Pasted image 20240304133752.png]]
- We could turn off pipelining
- Now latency of adder-multiplexer is 1, we get a single sum
- Turning off pipelining will unfortunately also reduce clock speed
![[Pasted image 20240304133907.png]]
- After the pipeline is full (it takes 13 cycles to fill), the first output of the pipeline (input\[1,0\] in this example) comes out and is added to the current input (input\[14,0\]). Hence there are 13 independent, interleaved summations in the pipeline.
![[Pasted image 20240304144655.png]]
- If we use the feedback design with the original input order (top left diagram), we get the wrong answer due to the latency of the pipeline. (The first output will be input\[1,0]+input\[14,0]+…, when we wanted input\[1,0]+input\[2,0]+…). To get the right answer, we need to rearrange the input data to account for the latency of the pipeline. If the input is a 2D array, this rearrangement looks like an array tiling and transpose (see bottom right).
![[Pasted image 20240304150554.png]]
- The C code is just to show you the original iteration order, and the effective iteration order needed to work with the hardware latency. Recall that C>=L, where L is the latency of the feedback path
![[Pasted image 20240304153328.png]]
